# ONT_demux Pipeline Tutorial: Execution
## Description:
The purpose of this tutorial is to demonstrate the overall workflow for ONT_demux. ONT_demux was designed to provide an end to end solution for demultiplexing and barcoding Oxford Nanopore reads. It can take raw fast5 files generated by Oxford Nanopore sequencers (ex. MinION), demultiplex, basecall, filter, and taxonomic classify sequencing reads. 
*This tutorial will detail the instructions to execute the pipeline. Extended workflow examples can be found [here]()*

## System Requirements:
ONT_demux utilizes the [Nextflow](https://www.nextflow.io/) workflow manager and requires a POSIX environment, such as the various flavors of linux or macOS. Through the use of Nextflow, ONT_demux can be run flexibly on a local machine, available high performance compute cluster, or on one of the various cloud providers. Due to the large demands of the various software tools, we **strongly recommend** utilizing an HPC environment with a minimum of 30 CPU cores and 180Gb of RAM per node, as well as Singularity (v3.5.2). The base configuration is designed for a slurm controller, but can be customized to fit your personal system as well. 

To install Nextflow you can follow the directions found [on their main page](https://www.nextflow.io/). In brief, ensure you have Java v8+ and then download the executable:
```
curl -s https://get.nextflow.io | bash
```
The nextflow executable can then be found in your current working directory, and can either be used as such or added to your user's PATH depending upon your needs. 
### Containerized execution
ONT_demux is designed to optimally work with containerized environments. Locally this is often [Docker](https://www.docker.com/), and in an HPC setting is [Singularity](https://sylabs.io/singularity/). To install Docker, please follow the [appropriate installation steps for your operating system.](https://docs.docker.com/get-docker/). To install Singularity, please contact your local HPC administrator to appropriately ensure the installation. 

When executing the pipeline, you can utilize the ```-profile docker``` or ```-profile singularity``` to automatically pull the appropriate containers for each step. 

### Full local execution
Full local execution is not recommended. If you are to do this, you must first install each individual tool per the developer's recommendations and ensure it is included in your PATH. Good luck...

## Metadata
Successful execution of this pipeline requires an accurate metadata table. This is a comma-delimited file (.csv) that contains the appropriate paths and sample names for the pipeline ingress. Examples can be found at [within the documentation](https://github.com/alemenze/bact-builder/tree/main/docs/metadata_examples). For this example, we will demonstrate making a table purely via command line, and will be demonstrating a full pipeline execution for a singular sample. If you are using a subset workflow, please ensure the metadata table contains the appropriate columns. 

```bash
touch metadata_example.csv
echo "sample_id,fast5_dir,fast5_dirname,ont_barcode,illumina_r1,illumina_r2" >> metadata_example.csv
echo "ExampleSample,/projectdir/MyFolder/ONT_Data/Run1/,Run1,barcode05,/projectdir/MyFolder/IlluminaData/ExampleSample_R1.fastq.gz,/projectdir/MyFolder/IlluminaData/ExampleSample_R2.fastq.gz" >> metadata_example.csv
```

## Pipeline Execution
Pipeline execution is most often run locally via Docker, through a slurm executor on an HPC (multi-node capacity), or via cloud resources. We will demonstrate each below assuming your data and nextflow are in your home directory. *Locally installed tools and single-node HPC execution are strongly discouraged and will not be demonstrated*

### Locally via Docker
```
~/nextflow run messyasza/ONT_demux -r main --samplesheet ~/metadata_example.csv
```

### Slurm executor on an HPC
In this case, we also will set it to run in the background. This is so we can easily log out of the HPC and ensure it continues running. 
```
module load java/11.0.5
module load singularity/3.5.2

nohup ~/nextflow -bg run messyasza/ONT_demux --samplesheet ~/metadata_example.csv -profile slurm --node_partition='node_partition' > output_log.txt
```

Additionally, if you have GPU access for dorado basecalling it is strongly recommended to utilize this. You must first ensure you are using Nvidia hardware with CUDA installed. 
```
module load java/11.0.5
module load singularity/3.5.2

nohup ~/nextflow -bg run messyasza/ONT_demux --samplesheet ~/metadata_example.csv -profile slurm --node_partition='node_partition' --gpu_active --gpus 1 --gpu_node_partition='gpu_partition' > output_log.txt
```
